etl.workflow.path=tasks
etl.default.delta.base.path=/tmp/delta

encrypt.algorithm=PBEWithMD5AndDES
encrypt.password=cGFzc3dvcmQ=

spark.default.spark.sql.catalogImplementation=hive
spark.default.spark.sql.legacy.createHiveTableByDefault=false
spark.default.spark.sql.hive.convertCTAS=true
spark.default.spark.sql.cbo.enabled=true
spark.default.spark.sql.adaptive.enabled=true
spark.default.spark.sql.adaptive.logLevel=info
spark.default.spark.sql.adaptive.advisoryPartitionSizeInBytes=128m
spark.default.spark.sql.adaptive.coalescePartitions.enabled=true
spark.default.spark.sql.adaptive.coalescePartitions.minPartitionNum=1
spark.default.spark.sql.adaptive.fetchShuffleBlocksInBatch=true
spark.default.spark.sql.adaptive.localShuffleReader.enabled=true
spark.default.spark.sql.adaptive.skewJoin.enabled=true
spark.default.spark.sql.adaptive.skewJoin.skewedPartitionFactor=5
spark.default.spark.sql.adaptive.skewJoin.skewedPartitionThresholdInBytes=400m
spark.default.spark.sql.adaptive.nonEmptyPartitionRatioForBroadcastJoin=0.2
spark.default.spark.sql.autoBroadcastJoinThreshold=-1
spark.default.spark.sql.adaptive.shuffle.targetPostShuffleInputSize=134217728
spark.default.hive.exec.dynamic.partition=true
spark.default.hive.exec.dynamic.partition.mode=nonstrict
spark.default.spark.sql.sources.partitionOverwriteMode=dynamic

flyway.driver=com.github.sharpdata.sharpetl.spark.extra.driver.SparkJdbcDriver
flyway.url=jdbc:spark_sharp_etl://localhost/sharp_etl
flyway.username=admin
flyway.password=admin


etl.default.jobId.column=job_id
etl.default.jobTime.column=job_time

from_file_path=true

